# BookWhisperer

Convert EPUB/TXT books to high-quality audiobooks using LLM and TTS.

## Overview

BookWhisperer is an audiobook generator that:
- Uses **Ollama (LLM)** to format and optimize text
- Uses **Chatterbox TTS** to generate audio
- Processes books chapter-by-chapter for efficient handling of large files

## Tech Stack

### Backend
- Python 3.11 + FastAPI
- PostgreSQL for metadata
- Redis + Celery for async tasks
- Ollama (local) for LLM formatting
- Chatterbox TTS for audio generation

### Frontend
- React 18 + TypeScript
- Vite build tool
- TailwindCSS for styling
- TanStack Query for state management

### Infrastructure
- Docker Compose with containers for PostgreSQL, Redis, Ollama
- Celery Workers for async processing
- Flower for Celery monitoring

## Project Structure

```
BookWhisperer/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py              # FastAPI application
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py            # Configuration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py          # DB connection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/              # SQLAlchemy models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas/             # Pydantic schemas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/v1/              # API endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/            # Business logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tasks/               # Celery tasks
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ alembic/                 # DB migrations
‚îÇ   ‚îú‚îÄ‚îÄ storage/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ uploads/             # EPUB/TXT files
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ audio/               # Generated audio
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îî‚îÄ‚îÄ docker-compose.yml
```

## Getting Started

### Prerequisites

- Docker and Docker Compose
- Python 3.11+ (for local development)
- Node.js 18+ (for frontend development)

### Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/BookWhisperer.git
cd BookWhisperer
```

2. Create environment file:
```bash
cd backend
cp .env.example .env
# Edit .env with your settings
```

3. Start services with Docker Compose:
```bash
docker-compose up -d
```

This will start:
- PostgreSQL (port 5432)
- Redis (port 6379)
- Ollama (port 11434)
- Chatterbox TTS (port 4123)
- Backend API (port 8000)
- Celery Worker
- Flower (port 5555)
- Frontend (port 3000)

4. Setup Ollama model (first time only):

**Linux/Mac:**
```bash
cd backend
chmod +x scripts/setup_ollama.sh
./scripts/setup_ollama.sh
```

**Windows:**
```bash
cd backend
scripts\setup_ollama.bat
```

This will download the LLM model (default: llama2). This may take several minutes.

5. Access the services:
- **Frontend UI**: http://localhost:3000
- **API Documentation**: http://localhost:8000/docs
- **Flower (Celery monitoring)**: http://localhost:5555

### Frontend Development

For local frontend development:

1. Install dependencies:
```bash
cd frontend
npm install
```

2. Create environment file:
```bash
cp .env.example .env
```

3. Start development server:
```bash
npm run dev
```

The frontend will be available at http://localhost:3000 with hot reload.

### Backend Development

For local backend development without Docker:

1. Install dependencies:
```bash
cd backend
pip install -r requirements.txt
```

2. Start PostgreSQL and Redis (via Docker):
```bash
docker-compose up -d db redis ollama
```

3. Run migrations:
```bash
cd backend
alembic upgrade head
```

4. Start the FastAPI server:
```bash
uvicorn app.main:app --reload
```

5. Start Celery worker (in another terminal):
```bash
cd backend
celery -A app.tasks.celery_app worker --loglevel=info
```

## API Endpoints

### Books
- `POST /api/v1/books/upload` - Upload EPUB/TXT file (auto-triggers parsing)
- `GET /api/v1/books` - List all books (with pagination)
- `GET /api/v1/books/{book_id}` - Get book details
- `PATCH /api/v1/books/{book_id}` - Update book
- `POST /api/v1/books/{book_id}/process` - Manually trigger book processing
- `DELETE /api/v1/books/{book_id}` - Delete book

### Chapters
- `GET /api/v1/books/{book_id}/chapters` - List all chapters for a book
- `GET /api/v1/chapters/{chapter_id}` - Get chapter details
- `POST /api/v1/chapters/{chapter_id}/format` - Format a single chapter with LLM
- `POST /api/v1/books/{book_id}/chapters/format` - Format all chapters for a book

### Jobs
- `GET /api/v1/jobs/{job_id}` - Get job status
- `GET /api/v1/jobs/books/{book_id}/jobs` - Get all jobs for a book
- `GET /api/v1/jobs/celery/{celery_task_id}` - Get job by Celery task ID

### Health
- `GET /api/v1/health` - API health check
- `GET /api/v1/health/db` - Check database connection
- `GET /api/v1/health/ollama` - Check Ollama connection
- `GET /api/v1/health/tts` - Check TTS connection
- `GET /api/v1/health/all` - Check all services

## Database Schema

### Tables

**books** - Uploaded books
- id, title, author, file_name, file_path, file_type
- total_chapters, status, error_message, metadata
- created_at, updated_at

**chapters** - Extracted chapters
- id, book_id, chapter_number, title
- raw_text, formatted_text, word_count, character_count
- status, error_message, created_at, updated_at

**audio_files** - Generated audio files
- id, chapter_id, file_path, file_size, duration_seconds
- format, chunk_index, total_chunks, tts_model, voice_id
- created_at

**processing_jobs** - Async task tracking
- id, book_id, chapter_id, job_type, celery_task_id
- status, progress_percent, error_message, retry_count
- started_at, completed_at, created_at, updated_at

## Current Status

**Phase 1 - Foundation** ‚úÖ COMPLETED
- Project structure created
- Docker Compose setup with PostgreSQL, Redis, Ollama
- Backend configuration files
- SQLAlchemy models (Book, Chapter, AudioFile, ProcessingJob)
- Pydantic schemas
- Alembic database migrations setup
- FastAPI application with CORS
- Books API endpoints (upload, list, get, update, delete)
- Health check endpoints
- Storage service for file management

**Phase 2 - Parsing & Extraction** ‚úÖ COMPLETED
- ‚úÖ EPUB parser service with chapter extraction
- ‚úÖ TXT parser service with heuristic chapter detection
- ‚úÖ Celery configuration with Redis broker
- ‚úÖ parse_book_task for async book processing
- ‚úÖ Chapters API endpoints
- ‚úÖ Jobs API endpoints for tracking task progress
- ‚úÖ Automatic parsing on upload
- ‚úÖ Celery Worker and Flower integration in Docker

**Phase 3 - LLM Formatting** ‚úÖ COMPLETED
- ‚úÖ Ollama Docker container integration
- ‚úÖ llm_formatter.py service with Ollama client
- ‚úÖ Text chunking service (chunking.py) for LLM and TTS
- ‚úÖ format_chapter_task Celery task
- ‚úÖ format_all_chapters_task for batch processing
- ‚úÖ POST /chapters/{id}/format endpoint
- ‚úÖ POST /books/{id}/chapters/format endpoint (batch)
- ‚úÖ Comprehensive test suite for formatter and chunking
- ‚úÖ Setup scripts for Ollama model pulling

**Phase 4 - TTS Integration** ‚è≠Ô∏è SKIPPED (for now)
- Phase 4 skipped to prioritize frontend development
- TTS integration can be added later

**Phase 5 - Frontend Development** ‚úÖ COMPLETED
- ‚úÖ React 18 + TypeScript + Vite setup
- ‚úÖ TailwindCSS with dark mode support
- ‚úÖ React Router for navigation
- ‚úÖ TanStack Query for state management
- ‚úÖ Complete API integration layer
- ‚úÖ BookUpload component with drag-and-drop
- ‚úÖ BookList with pagination
- ‚úÖ BookDetails component
- ‚úÖ ChapterList component
- ‚úÖ ProgressTracker with real-time polling
- ‚úÖ Production Docker build with Nginx
- ‚úÖ Responsive design for all screen sizes

**Phase 6 - Integration & Polish** ‚úÖ COMPLETED
- ‚úÖ Toast notification system (success, error, warning, info)
- ‚úÖ Confirmation dialogs for destructive actions
- ‚úÖ Enhanced error handling and user feedback
- ‚úÖ Smooth animations and transitions
- ‚úÖ Complete API documentation with examples
- ‚úÖ Comprehensive user guide
- ‚úÖ Production deployment guide
- ‚úÖ Security best practices documentation
- ‚úÖ Performance tuning guidelines
- ‚úÖ Backup and recovery procedures

**Status: PRODUCTION READY** üöÄ

## Configuration

Edit `backend/.env` to configure:

```env
# Database
DATABASE_URL=postgresql://bookwhisperer:password@localhost:5432/bookwhisperer

# Redis
REDIS_URL=redis://localhost:6379/0

# Ollama
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama2
OLLAMA_MAX_TOKENS=4000  # Max tokens per LLM request

# Storage
MAX_UPLOAD_SIZE=52428800  # 50MB
```

## Usage

### Using the Web Interface

1. **Open the frontend**: http://localhost:3000

2. **Upload a book**:
   - Drag and drop an EPUB or TXT file
   - Or click to browse and select a file
   - Optionally edit the title and author
   - Click "Upload & Process"

3. **View books**:
   - All uploaded books are listed on the home page
   - Click on a book to view details

4. **Format chapters**:
   - Click on a book to view its chapters
   - Click "Format All Chapters" to process with LLM
   - Or format individual chapters
   - Watch progress in real-time

5. **Monitor progress**:
   - ProgressTracker shows all active jobs
   - Progress bars update automatically
   - View detailed status and errors

### Using the API Directly

1. **Upload a book** (automatically triggers parsing):
```bash
curl -X POST "http://localhost:8000/api/v1/books/upload" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@mybook.epub" \
  -F "title=My Book" \
  -F "author=Author Name"
```

2. **Check book status**:
```bash
curl "http://localhost:8000/api/v1/books/{book_id}"
```

3. **List chapters** (after parsing completes):
```bash
curl "http://localhost:8000/api/v1/books/{book_id}/chapters"
```

4. **Monitor processing jobs**:
```bash
curl "http://localhost:8000/api/v1/jobs/books/{book_id}/jobs"
```

5. **Format chapters with LLM** (after parsing completes):
```bash
# Format a single chapter
curl -X POST "http://localhost:8000/api/v1/chapters/{chapter_id}/format"

# Or format all chapters for a book
curl -X POST "http://localhost:8000/api/v1/books/{book_id}/chapters/format"
```

6. **View Celery tasks in Flower**:
   - Open http://localhost:5555 in your browser
   - Monitor task progress, worker status, and task history

### Book Processing Flow

1. **Upload** ‚Üí Book file is saved to storage
2. **Parse** ‚Üí Celery task extracts chapters from EPUB/TXT
3. **Chapters Created** ‚Üí Raw text stored in database
4. **Format** ‚Üí LLM formats text for audiobook narration
5. **Generate Audio** ‚Üí TTS creates audio files (coming soon)
6. **Download** ‚Üí Get audiobook files (coming soon)

### Parser Features

**EPUB Parser**:
- Extracts chapters from table of contents
- Converts HTML to plain text
- Preserves chapter titles and structure
- Handles metadata (title, author, language)

**TXT Parser**:
- Detects chapters using pattern matching:
  - "Chapter 1", "CHAPTER I", etc.
  - Numbered sections: "1.", "I.", etc.
  - "Part 1", "PART I", etc.
- Auto-detects file encoding (UTF-8, Latin-1, etc.)
- Filters false positives (too short content)

### LLM Formatting Features

**Text Formatting with Ollama**:
- Cleans and normalizes text (fixes typos, punctuation)
- Ensures proper sentence structure and grammar
- Identifies and formats dialogue clearly
- Adds appropriate punctuation for natural pauses
- Removes formatting artifacts (HTML tags, special characters)
- Preserves original content and meaning

**Smart Chunking Strategy**:
- Automatically splits large chapters for LLM processing
- Preserves context with overlapping chunks (200 chars)
- Respects sentence and paragraph boundaries
- Handles edge cases (very long sentences, mixed content)
- Max chunk size: 3800 characters (configurable)
- Reassembles formatted chunks seamlessly

**Processing**:
- Async processing with Celery for scalability
- Progress tracking for each formatting job
- Retry logic with exponential backoff (3 retries max)
- Detailed error messages for debugging

## Documentation

BookWhisperer includes comprehensive documentation to help you get started, use the platform, and deploy to production:

### User Documentation
- **[User Guide](docs/USER_GUIDE.md)** - Complete guide for using BookWhisperer
  - Getting started
  - Uploading and managing books
  - Formatting chapters
  - Monitoring progress
  - Troubleshooting
  - FAQ

### Developer Documentation
- **[API Documentation](docs/API_DOCUMENTATION.md)** - Complete REST API reference
  - All endpoints with examples
  - Request/response formats
  - Error handling
  - Best practices

- **[Swagger UI](http://localhost:8000/docs)** - Interactive API documentation (when running)

### Operations Documentation
- **[Deployment Guide](docs/DEPLOYMENT.md)** - Production deployment guide
  - Server requirements
  - Installation steps
  - Security setup
  - Performance tuning
  - Monitoring and logging
  - Backup and recovery

### Implementation Summaries
- **[PHASE3_SUMMARY.md](PHASE3_SUMMARY.md)** - LLM formatting implementation
- **[PHASE5_SUMMARY.md](PHASE5_SUMMARY.md)** - Frontend development
- **[PHASE6_SUMMARY.md](PHASE6_SUMMARY.md)** - Integration and polish

## Features

### Current Features ‚ú®

- **Easy Book Upload** - Drag-and-drop EPUB and TXT files
- **Automatic Parsing** - Intelligent chapter detection
- **LLM Formatting** - Text optimization for audiobook narration
- **Real-time Progress** - Track all processing jobs
- **Toast Notifications** - Clear feedback on all actions
- **Confirmation Dialogs** - Prevent accidental data loss
- **Dark Mode** - Full dark mode support throughout
- **Responsive Design** - Works on desktop, tablet, and mobile
- **Celery Workers** - Async processing with retry logic
- **Flower Monitoring** - Task monitoring dashboard

### Coming Soon üöÄ

- Audio generation with TTS (Phase 4)
- Audio playback in browser
- Download audiobooks as ZIP
- Multiple voice options
- User authentication
- Book search and filtering
- Batch operations

## Development Notes

- Database tables are created automatically on startup
- Upload size limit: 50MB (configurable)
- Supported file types: EPUB, TXT
- API documentation available at `/docs` (Swagger UI)
- Celery tasks run asynchronously with retry logic (3 retries max)
- Processing jobs are tracked in the database for monitoring

## Troubleshooting

For common issues, see the [User Guide Troubleshooting section](docs/USER_GUIDE.md#troubleshooting).

For deployment issues, see the [Deployment Guide Troubleshooting section](docs/DEPLOYMENT.md#troubleshooting).

## License

MIT

## Contributing

Contributions are welcome! Please open an issue or submit a pull request.

### Development Setup

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests (when available)
5. Submit a pull request

## Support

- **Documentation:** See docs/ directory
- **Issues:** [GitHub Issues](https://github.com/yourusername/BookWhisperer/issues)
- **Discussions:** [GitHub Discussions](https://github.com/yourusername/BookWhisperer/discussions)
